{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Model with Logistic Regression & Multinomial Naive Bayes\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, our main purpose is to create our first model using our `both_subreddits.csv` dataset that we fully cleaned and explored back in our [EDA](http://localhost:8888/lab/tree/projects/project_3/EDA.ipynb) notebook.  The models that we will touch on are below:\n",
    "\n",
    "- Logistic Regression\n",
    "- Count Vectorizer\n",
    "- Tfidf Vectorizer\n",
    "- Multinomial Naive Bayes\n",
    "- Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   author               10000 non-null  object\n",
      " 1   created_utc          10000 non-null  int64 \n",
      " 2   selftext             10000 non-null  object\n",
      " 3   subreddit            10000 non-null  object\n",
      " 4   title                10000 non-null  object\n",
      " 5   title_word_count     10000 non-null  int64 \n",
      " 6   selftext_word_count  10000 non-null  int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 547.0+ KB\n"
     ]
    }
   ],
   "source": [
    "subreddits = pd.read_csv('./data/both_subreddits.csv')\n",
    "subreddits.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before we get too far into our modeling, let's first create binary categories for our 1st and 2nd subreddits.\n",
    "\n",
    "- `r/explainlikeimfive` = 1\n",
    "- `r/Advice` = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits['subreddit'] = subreddits['subreddit'].map({'explainlikeimfive': 1, 'Advice': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a stemming device to shorten words to root or _lemma_.  Code based on [StackOverflow](https://stackoverflow.com/questions/36182502/add-stemming-support-to-countvectorizer-sklearn) question.  This will be used in the Pipeline section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def porter(text):\n",
    "    return (stemmer.stem(w) for w in analyzer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = subreddits['title']\n",
    "y = subreddits['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500,), (7500,))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2500,), (2500,))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5756    0\n",
       "2721    1\n",
       "5955    0\n",
       "4972    1\n",
       "5897    0\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "This is where I will use `CountVectorizer` to:\n",
    "\n",
    "- get rid of stopwords\n",
    "- get rid of 'ELI5:' which is how `r/explainlikeimfive` users like to format their prompts\n",
    "- create vectors for words that I will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5012\n",
       "1    0.4988\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding 'eli5' as a stop word to make it harder to differentiate between 2 subreddits:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original code:  https://stackoverflow.com/questions/24386489/adding-words-to-scikit-learns-countvectorizers-stop-list\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(['eli5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Pipeline\n",
    "\n",
    "**...with `CountVectorizer()`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:   41.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross validation score: 0.9212\n",
      "Best parameters to use: {'cvec__max_df': 1.0, 'cvec__max_features': 7000, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': ['eli5']}\n",
      "Testing score: 0.9236\n"
     ]
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'cvec__stop_words': [stop_words, ['eli5']],\n",
    "    'cvec__max_df': [1.0, 0.80, 0.90],\n",
    "    'cvec__max_features': [9000],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                  param_grid = pipe_params,\n",
    "                  cv=5,\n",
    "                  verbose = 1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best cross validation score: {gs.best_score_}')\n",
    "print(f'Best parameters to use: {gs.best_params_}')\n",
    "print(f'Testing score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**...with `CountVectorizer()` and `PorterStemmer()`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(analyzer=porter)),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "# The X_train used here was just the title column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross validation score: 0.9888\n",
      "Best parameters to use: {'cvec__max_features': 10000, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': frozenset({'until', 'there', 'although', 'am', 're', 'top', 'his', 'forty', 'seems', 'you', 'become', 'move', 'someone', 'anyway', 'ever', 'has', 'have', 'they', 'nobody', 'whoever', 'my', 'amongst', 'two', 'i', 'below', 'however', 'before', 'and', 'thence', 'it', 'yet', 'mostly', 'twelve', 'to', 'fifteen', 'since', 'either', 'done', 'wherein', 'because', 'could', 'per', 'each', 'which', 'every', 'please', 'themselves', 'what', 'further', 'becomes', 'such', 'would', 'rather', 'seemed', 'above', 'therein', 'though', 'cry', 'than', 'is', 'other', 'whom', 'will', 'still', 'more', 'six', 'became', 'itself', 'always', 'its', 'thereupon', 'call', 'never', 'due', 'eight', 'whole', 'who', 'system', 'after', 'how', 'our', 'out', 'as', 'that', 'thin', 'about', 'them', 'sixty', 'behind', 'formerly', 'keep', 'full', 'own', 'under', 'go', 'your', 'elsewhere', 'hereby', 'co', 'everything', 'no', 'anyone', 'here', 'back', 'four', 'sometime', 'towards', 'an', 'sincere', 'across', 'whatever', 'everyone', 'him', 'a', 'thereby', 'were', 'nevertheless', 'fire', 'in', 'ten', 'us', 'others', 'she', 'alone', 'almost', 'serious', 'whose', 'sometimes', 'upon', 'beforehand', 'also', 'couldnt', 'her', 'un', 'can', 'find', 'very', 'so', 'this', 'into', 'with', 'anything', 'among', 'any', 'hereupon', 'somewhere', 'only', 'where', 'why', 'along', 'side', 'ourselves', 'nowhere', 'had', 'inc', 'might', 'front', 'moreover', 'on', 'meanwhile', 'except', 'describe', 'fifty', 'nothing', 'herein', 'some', 'mill', 'first', 'made', 'whereafter', 'within', 'cannot', 'thereafter', 'thru', 'nor', 'these', 'interest', 'those', 'even', 'give', 'be', 'five', 'cant', 'must', 'wherever', 'all', 'throughout', 'against', 'whereby', 'the', 'con', 'seeming', 'whence', 'perhaps', 'ltd', 'three', 'neither', 'found', 'show', 'next', 'not', 'himself', 'many', 'enough', 'hasnt', 'eg', 'whither', 'now', 'name', 'ie', 'we', 'should', 'via', 'several', 'afterwards', 'most', 'seem', 'without', 'yours', 'of', 'whereas', 'hundred', 'again', 'besides', 'bottom', 'none', 'get', 'see', 'do', 'nine', 'yourself', 'put', 'detail', 'too', 'else', 'least', 'through', 'few', 'already', 'everywhere', 'me', 'hers', 'whereupon', 'beside', 'anywhere', 'becoming', 'been', 'from', 'therefore', 'empty', 'well', 'their', 'indeed', 'around', 'while', 'take', 'onto', 'less', 'are', 'over', 'he', 'last', 'thick', 'beyond', 'between', 'toward', 'for', 'de', 'former', 'latterly', 'then', 'both', 'if', 'once', 'but', 'namely', 'yourselves', 'myself', 'one', 'amoungst', 'part', 'eleven', 'up', 'amount', 'fill', 'somehow', 'when', 'something', 'whether', 'down', 'during', 'may', 'hence', 'was', 'at', 'latter', 'whenever', 'often', 'etc', 'ours', 'mine', 'noone', 'another', 'by', 'much', 'same', 'or', 'hereafter', 'together', 'thus', 'being', 'otherwise', 'twenty', 'anyhow', 'bill', 'eli5', 'third', 'herself', 'off'})}\n",
      "Testing score: 0.9892\n"
     ]
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'cvec__stop_words': [stop_words, ['eli5']],\n",
    "    'cvec__max_features': [10_000, 12_000],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                  param_grid = pipe_params,\n",
    "                  cv=5,\n",
    "                  verbose = 1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best cross validation score: {gs.best_score_}')\n",
    "print(f'Best parameters to use: {gs.best_params_}')\n",
    "print(f'Testing score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**...with `TfidfVectorizer`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross validation score: 0.9102666666666666\n",
      "Best parameters to use: {'tfidf__stop_words': ['eli5']}\n",
      "Testing score: 0.9128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "# BASE MODEL WITH ONLY STOP_WORDS PUT IN\n",
    "\n",
    "pipe_params = {\n",
    "    'tfidf__stop_words': [stop_words, ['eli5']],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                  param_grid = pipe_params,\n",
    "                  cv=5,\n",
    "                  verbose = 1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best cross validation score: {gs.best_score_}')\n",
    "print(f'Best parameters to use: {gs.best_params_}')\n",
    "print(f'Testing score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:   33.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross validation score: 0.9209333333333334\n",
      "Best parameters to use: {'tfidf__max_df': 1.0, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': ['eli5']}\n",
      "Testing score: 0.9176\n"
     ]
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'tfidf__stop_words': [stop_words, ['eli5']],\n",
    "    'tfidf__max_df': [1.0, 0.80, 0.90],\n",
    "    'tfidf__max_features': [3000, 5000, 7000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                  param_grid = pipe_params,\n",
    "                  cv=5,\n",
    "                  verbose = 1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best cross validation score: {gs.best_score_}')\n",
    "print(f'Best parameters to use: {gs.best_params_}')\n",
    "print(f'Testing score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes and `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_multi = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross validation score: 0.9233333333333335\n",
      "Best parameters to use: {'tfidf__max_features': 11000, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': ['eli5']}\n",
      "Testing score: 0.9244\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'tfidf__stop_words': [stop_words, ['eli5']],\n",
    "    'tfidf__max_features': [10500, 11000, 11300],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_multi,\n",
    "                  param_grid = params,\n",
    "                  cv=5,\n",
    "                  verbose = 1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best cross validation score: {gs.best_score_}')\n",
    "print(f'Best parameters to use: {gs.best_params_}')\n",
    "print(f'Testing score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Conclusion:\n",
    "\n",
    "I am surprised to see the best parameters as not using the stop words and rather just using all words.  This yielded a better result.  Perhaps, the model is automatically understanding that more common words don't mean much to it as it sees it across the entire dataset.\n",
    "\n",
    "In conclusion, here are the best parameters for `CountVectorizer()`:\n",
    "\n",
    "- `'cvec__max_df': 1.0`\n",
    "- `'cvec__max_features': 7000`\n",
    "- `'cvec__ngram_range': (1, 2)`\n",
    "- `'cvec__stop_words': ['eli5']`\n",
    "\n",
    "to yield a score of 0.9212 for the training data and **0.9236** on the **testing** data.  I am satisfied to see that my model is not overfit nor is it biased.\n",
    "\n",
    "Here are the best parameters for `TfidfVectorizer()`:\n",
    "\n",
    "- `'cvec__max_df': 1.0`\n",
    "- `'cvec__max_features': 5000`\n",
    "- `'cvec__ngram_range': (1, 2)`\n",
    "- `'cvec__stop_words': ['eli5']`\n",
    "\n",
    "to yield a score of 0.9209 for the training data and **0.9176** on the **testing** data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A second attempt with the `text` column:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = subreddits['text']\n",
    "y = subreddits['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500,), (7500,))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2500,), (2500,))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5012\n",
       "1    0.4988\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_multi = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   57.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross validation score: 0.9507999999999999\n",
      "Best parameters to use: {'tfidf__max_features': 11300, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': ['eli5']}\n",
      "Testing score: 0.9528\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'tfidf__stop_words': [stop_words, ['eli5']],\n",
    "    'tfidf__max_features': [10500, 11000, 11300],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_multi,\n",
    "                  param_grid = params,\n",
    "                  cv=5,\n",
    "                  verbose = 1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best cross validation score: {gs.best_score_}')\n",
    "print(f'Best parameters to use: {gs.best_params_}')\n",
    "print(f'Testing score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions for confusion matrix\n",
    "predictions = gs.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992019154030327"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating sensitivity\n",
    "tn / (tn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4c17e67a6ba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# code taken from NLP II lesson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxkcd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greens'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# code taken from NLP II lesson\n",
    "plot_confusion_matrix(gs, X_test, y_test, cmap='Greens', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In conclusion:\n",
    "\n",
    "Bringing in `selftext` and using a `PorterStemmer` made a huge big difference in testing scores.\n",
    "\n",
    "Best parameters for `CountVectorizer` and `LogisticRegression` with a `PorterStemmer` are:\n",
    "\n",
    "- `cvec__max_features`: `10000`\n",
    "- `stop_words`: `stop_words` list\n",
    "- `cvec__ngram_range`: `(1, 1)`\n",
    "\n",
    "yielding a training score of 0.9888 and a **testing score** of **0.9892**\n",
    "\n",
    "Best parameters for `TfidfVectorizer` and `MultinomialNB` are:\n",
    "\n",
    "- `tfidf__stop_words`:  `['eli5']`\n",
    "- `tfidf__max_features`:  `11300`\n",
    "- `tfidf__ngram_range`:  `(1, 2)`\n",
    "\n",
    "yielding a training score of 0.9508 and a **testing score** of **0.9528**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
